names_glue = "{Model}_{.value}"
)
# Convert to flextable for Word output
ft <- flextable(all_results_wide) %>%
theme_vanilla() %>%
autofit()
# Print the flextable
print(ft)
install.packages("devtools")
install.packages("devtools")
?pnorm
pnorm(90, mean = 70, sd = 15, lower.tail = FALSE, log.p = FALSE)
rnorm(7)
rnorm(1, mean = 0, sd = 1)
rnorm(1,0,1)
rnorm(40,70,15)
set.seed(123)
rnorm(40,70,15)
data <- rnorm(40,70,15)
summary(data)
ek<- 2
mu_data <- mean(data)
sd_data <-
sd_data<-sd(data)
crit<- qnorm(p = 0.975)
lower <- mu_data - crit*sd_data
upper <- mu_data + crit*sd_data
conf_int <- c(lower, upper)
install_github("SMAC-Group/introDS")
install.packages("githubinstall")
install_github("SMAC-Group/introDS")
library(githubinstall)
("SMAC-Group/introDS")
X<-2
##De Rossi
#Question 1, to set seed and generate 100 obs, I did the following:
set.seed(123)
n <- 100
#True prob. for Bin(1,pi)
pi_true <- 0.7
obs <- rbinom(n, size = 1, prob = pi_true)
# Question 2, to compute (π-hat) which is the sample proportion
pi_hat <- mean(obs)
pi_hat
# for question 3, to calculate the cdf, since, the quantile function is 0.975
k <- qnorm(0.975)
k
# from question 4, to calculate the bounds (upper and lower) for the confidence interval
#where (π_u) is upper bound and ((π_l)is lower bound
# Lower bound
pi_l <- pi_hat - k * sqrt((pi_hat * (1 - pi_hat)) / n)
pi_l
# Upper bound
pi_u <- pi_hat + k * sqrt((pi_hat * (1 - pi_hat)) / n)
pi_u
# Question 5
if (pi_true >= pi_l & pi_true <= pi_u) {
cat("The t-value of π lies within the confidence interval.\n")
} else {
cat("The t-value of π does not lie within the confidence interval.\n")
}
library(ggplot2)
data<-mpg
library(ggplot2)
data<-mpg
summary(data)
reg<-lm(hwy ~ ., data=mpg)
library(ggplot2)
data<-mpg
summary(data)
#for question 3.2, to run regression
reg<-lm(hwy ~ ., data=mpg)
library(ggplot2)
data <- mpg
summary(data)
reg<-lm(hwy ~ ., data=mpg)
library(ggplot2)
data <- mpg
summary(data)
#for question 3.2, to run regression
fit<-lm(hwy ~ ., data=mpg)
summary(fit)
# Load necessary libraries
library(MASS)      # For mvrnorm
library(wv)        # For wvar()
library(wavelets)  # For wavelet filters
# Parameters for the simulation
B <- 100         # Number of replications
d <- 1000        # Sample size
cont <- 10       # Number of contaminated observations
true_theta <- 2  # True parameter value
lambda <- 0.5    # Rate parameter for exponential contamination
# Initialize all objects to store results in one line
theta_Xt_std <- theta_Xt_rob <- theta_Zt_std <- theta_Zt_rob <- numeric(B)
# Simulation loop
for (b in 1:B) {
# Generate X: Multivariate normal with mean 0 and covariance matrix I_d * true_theta
X <- mvrnorm(n = 1, mu = rep(0, d), Sigma = diag(d) * true_theta)
# Create Z: Contaminated version of X
Z <- X
modified_indices <- sample(1:d, cont)  # Randomly select 'cont' indices
Z[modified_indices] <- rexp(cont, rate = lambda)  # Replace with exponential contamination
# Empirical wavelet variance for X
nu_hat_X_std <- wvar(X, robust = FALSE)$variance
nu_hat_X_rob <- wvar(X, robust = TRUE)$variance
# Empirical wavelet variance for Z
nu_hat_Z_std <- wvar(Z, robust = FALSE)$variance
nu_hat_Z_rob <- wvar(Z, robust = TRUE)$variance
# Apply GMWM to X using standard and robust estimators
result_X_std <- gmwm(X, J = floor(log2(d)) - 1, robust = FALSE, start = var(X))
theta_Xt_std[b] <- result_X_std$theta_hat
result_X_rob <- gmwm(X, J = floor(log2(d)) - 1, robust = TRUE, start = var(X))
theta_Xt_rob[b] <- result_X_rob$theta_hat
# Apply GMWM to Z using standard and robust estimators
result_Z_std <- gmwm(Z, J = floor(log2(d)) - 1, robust = FALSE, start = var(Z))
theta_Zt_std[b] <- result_Z_std$theta_hat
result_Z_rob <- gmwm(Z, J = floor(log2(d)) - 1, robust = TRUE, start = var(Z))
theta_Zt_rob[b] <- result_Z_rob$theta_hat
}
wv_theo <- function(theta, J) {
# Initialize vector to store theo wv for each level
wv <- numeric(J)
# Loop through each level j
for (j in 1:J) {
# get wavelet filter for level j
wavelet_filter <- wt.filter(filter = "haar", level = j)@h
# Cal Aj = hj %*% t(hj), here hj is the wavelet filter
Aj <- wavelet_filter %*% t(wavelet_filter)
# Compute Σj(theta) = I_{2^j} * theta
d <- nrow(Aj) # Dimension of Aj, which is 2^j
Sigma_j <- diag(d) * theta
# Compute trace(Aj * Σj(theta)) and scale by 2^j
wv[j] <- sum(diag(Aj %*% Sigma_j)) / (2^j)
}
return(wv) # Return vector of theo. wavelet variances
}
gmwm_loss <- function(theta, nu_hat, J) {
# Compute the theoretical wavelet variance using the wv_theo function
nu_theta <- wv_theo(theta, J)
# Define the matrix Ω as the identity matrix
Omega <- diag(J)
# Compute the difference between empirical and theoretical wavelet variances
diff <- nu_hat - nu_theta
# Cal the loss: (ν̂ - ν(θ))ᵀ Ω (ν̂ - ν(θ))
loss <- t(diff) %*% Omega %*% diff
# Return the loss value
return(as.numeric(loss))
}
gmwm <- function(x, J, robust = FALSE, start = var(x), ...) {
# Compute the empirical wavelet variance (robust or standard)
if (robust) {
nu_hat <- wvar(x, robust = TRUE)$variance
} else {
nu_hat <- wvar(x)$variance
}
# Define the loss function for optimization
loss_function <- function(theta) {
gmwm_loss(theta, nu_hat, J)
}
# Optimize the loss function to find the parameter theta
theta_hat <- suppressWarnings(
optim(start, loss_function, method = "BFGS", ...)$par
)
# Return the estimated parameter and empirical wavelet variance
return(list(theta_hat = theta_hat, nu_hat = nu_hat))
}
# libraries
library(MASS)
library(wv)
library(wavelets)
# Parameters for the simulation
B <- 100         # No of replications
d <- 1000        # Sample size
cont <- 10       # No of contaminated obs
true_theta <- 2  # True parameter
lambda <- 0.5    # Rate parameter for exponential contamination
# Initialize objects to store results
theta_Xt_std <- numeric(B)
theta_Xt_rob <- numeric(B)
theta_Zt_std <- numeric(B)
theta_Zt_rob <- numeric(B)
# Simulation loop
for (b in 1:B) {
# Generate X: Multivariate normal with mean 0 and covariance matrix I_d * true_theta
X <- mvrnorm(n = 1, mu = rep(0, d), Sigma = diag(d) * true_theta)
# Create Z: Contaminated version of X
Z <- X
modified_indices <- sample(1:d, cont)  # Randomly select 'cont' indices
Z[modified_indices] <- rexp(cont, rate = lambda)  # Replace with exponential contamination
# Empirical wavelet variance for X
nu_hat_X_std <- wvar(X, robust = FALSE)$variance
nu_hat_X_rob <- wvar(X, robust = TRUE)$variance
# Empirical wavelet variance for Z
nu_hat_Z_std <- wvar(Z, robust = FALSE)$variance
nu_hat_Z_rob <- wvar(Z, robust = TRUE)$variance
# Apply GMWM to X using standard and robust estimators
result_X_std <- gmwm(X, J = floor(log2(d)) - 1, robust = FALSE, start = var(X))
theta_Xt_std[b] <- result_X_std$theta_hat
result_X_rob <- gmwm(X, J = floor(log2(d)) - 1, robust = TRUE, start = var(X))
theta_Xt_rob[b] <- result_X_rob$theta_hat
# Apply GMWM to Z using standard and robust estimators
result_Z_std <- gmwm(Z, J = floor(log2(d)) - 1, robust = FALSE, start = var(Z))
theta_Zt_std[b] <- result_Z_std$theta_hat
result_Z_rob <- gmwm(Z, J = floor(log2(d)) - 1, robust = TRUE, start = var(Z))
theta_Zt_rob[b] <- result_Z_rob$theta_hat
}
# Store results
results <- list(
theta_Xt_std = theta_Xt_std,
theta_Xt_rob = theta_Xt_rob,
theta_Zt_std = theta_Zt_std,
theta_Zt_rob = theta_Zt_rob
)
# Display a summary of results
summary(results)
# Compute Median Absolute Error (MAE)
mae_Xt_std <- median(abs(theta_Xt_std - true_theta))  # MAE for standard estimator on X
mae_Xt_rob <- median(abs(theta_Xt_rob - true_theta))  # MAE for robust estimator on X
mae_Zt_std <- median(abs(theta_Zt_std - true_theta))  # MAE for standard estimator on Z
mae_Zt_rob <- median(abs(theta_Zt_rob - true_theta))  # MAE for robust estimator on Z
# Display MAE results
cat("MAE for standard estimator on X:", mae_Xt_std, "\n") # Standard X results
cat("MAE for robust estimator on X:", mae_Xt_rob, "\n")   # Robust X results
cat("MAE for standard estimator on Z:", mae_Zt_std, "\n") # Standard Z results
cat("MAE for robust estimator on Z:", mae_Zt_rob, "\n")   # Robust Z results
# Create boxplots to compare estimators visually
boxplot(
cbind(theta_Xt_std, theta_Xt_rob, theta_Zt_std, theta_Zt_rob),
col = c("blue", "green", "red", "purple"),
names = c("Standard X", "Robust X", "Standard Z", "Robust Z"),
main = "Comparison of Estimators",
ylab = "Estimated Theta",
ylim = c(1.5, 2.5)  # Focus on values around the true parameter (2.0)
)
# Add a reference line for the true parameter value
abline(h = true_theta, col = "black", lty = 2)
# Compute Median Absolute Error (MAE)
mae_Xt_std <- median(abs(theta_Xt_std - true_theta))  # MAE for standard estimator on X
mae_Xt_rob <- median(abs(theta_Xt_rob - true_theta))  # MAE for robust estimator on X
mae_Zt_std <- median(abs(theta_Zt_std - true_theta))  # MAE for standard estimator on Z
mae_Zt_rob <- median(abs(theta_Zt_rob - true_theta))  # MAE for robust estimator on Z
# Display MAE results
cat("MAE for standard estimator on X:", mae_Xt_std, "\n") # Standard X results
cat("MAE for robust estimator on X:", mae_Xt_rob, "\n")   # Robust X results
cat("MAE for standard estimator on Z:", mae_Zt_std, "\n") # Standard Z results
cat("MAE for robust estimator on Z:", mae_Zt_rob, "\n")   # Robust Z results
# Create boxplots
par(mar = c(4, 4, 2, 1))
boxplot(
cbind(theta_Xt_std, theta_Xt_rob, theta_Zt_std, theta_Zt_rob),
col = c("blue", "green", "red", "purple"),
names = c("Standard X", "Robust X", "Standard Z", "Robust Z"),
main = "Comparison of Estimators",
ylab = "Estimated Theta",
ylim = c(1.5, 2.5)  # Focus on values around the true parameter (2.0)
)
# Add a reference line for the true parameter value
abline(h = true_theta, col = "black", lty = 2)
# Parameters for the simulation
B <- 100         # Number of replications
d <- 1000        # Sample size
cont <- 10       # Number of contaminated observations
true_theta <- 2  # True parameter
lambda <- 0.5    # Rate parameter for exponential contamination
# Initialize objects to store results
theta_Xt_std <- theta_Xt_rob <- theta_Zt_std <- theta_Zt_rob <- numeric(B)
# Define the model and constants
model <- WN()
J <- floor(log2(d)) - 1
# Simulation loop
for (b in 1:B) {
# Generate X: Time series from N(0, true_theta)
X <- rnorm(d, mean = 0, sd = sqrt(true_theta))
# Create Z: Contaminated version of X
Z <- X
modified_indices <- sample(1:d, cont)  # Randomly select 'cont' indices
Z[modified_indices] <- rexp(cont, rate = lambda)  # Replace with exponential contamination
# Apply GMWM to X using standard and robust estimators
result_X_std <- gmwm(model, X, J = J, robust = FALSE, start = list(sigma2 = var(X)))
theta_Xt_std[b] <- result_X_std$estimate
result_X_rob <- gmwm(model, X, J = J, robust = TRUE, start = list(sigma2 = var(X)))
theta_Xt_rob[b] <- result_X_rob$estimate
# Apply GMWM to Z using standard and robust estimators
result_Z_std <- gmwm(model, Z, J = J, robust = FALSE, start = list(sigma2 = var(Z)))
theta_Zt_std[b] <- result_Z_std$estimate
result_Z_rob <- gmwm(model, Z, J = J, robust = TRUE, start = list(sigma2 = var(Z)))
theta_Zt_rob[b] <- result_Z_rob$estimate
}
devtools::document()
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4")
devtools::document()
devtools::document()
devtools::document()
devtools::document()
?logitreg_group4
prob <- 1 / (1 + exp(-prepared_data$X %*% result$beta))
# Load required library
library(stats)
# 1. Prepare Design Matrix for Numerical, Date, and Factor Data Types
prepare_data <- function(data, response) {
# Create the design matrix using model.matrix
response_var <- as.numeric(data[[response]])
predictors <- model.matrix(as.formula(paste(response, "~ .")), data = data)[, -1]
list(X = predictors, y = response_var)
}
# 2. Logistic Regression Estimation Using Numerical Optimization
estimate_beta <- function(data, response) {
# Prepare design matrix and response variable
prepared_data <- prepare_data(data, response)
X <- prepared_data$X
y <- prepared_data$y
# Initial values using least squares
beta_initial <- solve(t(X) %*% X) %*% t(X) %*% y
# Log-likelihood function
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X %*% beta))
# Add a small value to p to prevent log(0)
p <- pmin(pmax(p, .Machine$double.eps), 1 - .Machine$double.eps)
-sum(y * log(p) + (1 - y) * log(1 - p))
}
# Optimization using optim
opt <- optim(
par = beta_initial,
fn = log_likelihood,
method = "BFGS"
)
list(beta = opt$par, value = opt$value, convergence = opt$convergence)
}
# 3. Bootstrap Confidence Intervals
bootstrap_ci <- function(data, response, beta_hat, n_bootstrap = 20, alpha = 0.05) {
prepared_data <- prepare_data(data, response)
X <- prepared_data$X
y <- prepared_data$y
n <- nrow(X)
p <- length(beta_hat)
bootstrap_estimates <- matrix(NA, nrow = n_bootstrap, ncol = p)
for (i in 1:n_bootstrap) {
# Resample the data
indices <- sample(1:n, size = n, replace = TRUE)
X_boot <- X[indices, , drop = FALSE]
y_boot <- y[indices]
# Re-estimate beta
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X_boot %*% beta))
# Add a small value to p to prevent log(0)
p <- pmin(pmax(p, .Machine$double.eps), 1 - .Machine$double.eps)
-sum(y_boot * log(p) + (1 - y_boot) * log(1 - p))
}
beta_boot <- optim(
par = beta_hat,
fn = log_likelihood,
method = "BFGS"
)$par
bootstrap_estimates[i, ] <- beta_boot
}
# Compute confidence intervals
ci <- apply(bootstrap_estimates, 2, function(x) {
quantile(x, probs = c(alpha / 2, 1 - alpha / 2), na.rm = TRUE)
})
t(ci)  # Transpose for clarity
}
# 4. Predict Classes Based on Cutoff 0.5
predict_class <- function(beta, X) {
prob <- 1 / (1 + exp(-X %*% beta))
as.integer(prob > 0.5)
}
# 5. Confusion Matrix and Metrics (Adjusted)
confusion_matrix <- function(data, response, beta) {
prepared_data <- prepare_data(data, response)
X <- prepared_data$X
y <- prepared_data$y
predictions <- predict_class(beta, X)
# Confusion matrix components
tp <- sum(predictions == 1 & y == 1)  # True Positives
tn <- sum(predictions == 0 & y == 0)  # True Negatives
fp <- sum(predictions == 1 & y == 0)  # False Positives
fn <- sum(predictions == 0 & y == 1)  # False Negatives
# Total actual positives and negatives
actual_positives <- tp + fn
actual_negatives <- tn + fp
predicted_positives <- tp + fp
predicted_negatives <- tn + fn
# Metrics with checks to avoid division by zero
prevalence <- mean(y)
accuracy <- (tp + tn) / (tp + tn + fp + fn)
sensitivity <- ifelse(actual_positives > 0, tp / actual_positives, NA)
specificity <- ifelse(actual_negatives > 0, tn / actual_negatives, NA)
false_discovery_rate <- ifelse(predicted_positives > 0, fp / predicted_positives, NA)
dor_denominator <- fp * fn
diagnostic_odds_ratio <- ifelse(dor_denominator > 0, (tp * tn) / dor_denominator, NA)
# Confusion matrix as a table
conf_matrix <- matrix(c(tp, fp, fn, tn), nrow = 2, byrow = TRUE,
dimnames = list("Predicted" = c("1", "0"), "Actual" = c("1", "0")))
list(
confusion_matrix = conf_matrix,
prevalence = prevalence,
accuracy = accuracy,
sensitivity = sensitivity,
specificity = specificity,
false_discovery_rate = false_discovery_rate,
diagnostic_odds_ratio = diagnostic_odds_ratio
)
}
# 6. Example Usage with Simulated Data
set.seed(123)
data <- data.frame(
x1 = rnorm(100),
x2 = as.factor(sample(c("A", "B"), 100, replace = TRUE)),
x3 = as.Date('2023-01-01') + sample(1:100, 100),
y = rbinom(100, 1, 0.5)
)
# Estimate beta
result <- estimate_beta(data, "y")
cat("Estimated Beta Coefficients:\n")
print(result$beta)
# Bootstrap Confidence Intervals
ci <- bootstrap_ci(data, "y", result$beta, n_bootstrap = 100, alpha = 0.05)
cat("\nBootstrap Confidence Intervals:\n")
print(ci)
# Confusion Matrix and Metrics
metrics <- confusion_matrix(data, "y", result$beta)
cat("\nConfusion Matrix:\n")
print(metrics$confusion_matrix)
cat("\nMetrics:\n")
cat("Prevalence:", metrics$prevalence, "\n")
cat("Accuracy:", metrics$accuracy, "\n")
cat("Sensitivity:", metrics$sensitivity, "\n")
cat("Specificity:", metrics$specificity, "\n")
cat("False Discovery Rate:", metrics$false_discovery_rate, "\n")
cat("Diagnostic Odds Ratio:", metrics$diagnostic_odds_ratio, "\n")
devtools::document()
Run `rm(list = c("bootstrap_ci", "confusion_matrix", "estimate_beta", "predict_class", "prepare_data"))` to remove the conflicts.
devtools::document()
rm(list = c("bootstrap_ci", "confusion_matrix", "estimate_beta", "predict_class", "prepare_data"))
rm(list = c("bootstrap_ci", "confusion_matrix", "estimate_beta", "predict_class", "prepare_data"))
devtools::document()
?logitreg_group4
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4")
devtools::install()
library(devtools)
devtools::check()
devtools::document()
devtools::document()
devtools::document()
setwd("~/Group4")
devtools::document()
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4")
devtools::document()
devtools::document()
install.packages("usethis")
library(usethis)
# Set package name and title
usethis::use_description(fields = list(
Package = "logitreg_Group4",
Title = "Supervised Binary Classification Using Logistic Regression",
Version = "0.1.0",
Description = "Provides functions for supervised binary classification using logistic regression. It includes methods to compute initial coefficients, calculate bootstrap confidence intervals, and generate confusion matrices with associated performance metrics. Users can input their own datasets and specify predictors and response variables dynamically.",
License = "GPL-3",
Encoding = "UTF-8",
LazyData = "true",
RoxygenNote = "7.3.1"
))
install.packages("usethis")
devtools::document()
devtools::document()
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4")
# Replace with your package path
path_desc <- "C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4"
desc_content <- read.dcf(path_desc)
# Corrected path to the DESCRIPTION file
path_desc <- "C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4/DESCRIPTION"
desc_content <- read.dcf(path_desc)
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4")
devtools::document()
# Specify the correct path to the DESCRIPTION file
path_desc <- "C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4/DESCRIPTION"
# Attempt to read the DESCRIPTION file
desc_content <- read.dcf(path_desc)
devtools::document()
devtools::document()
# Set the correct path to your DESCRIPTION file
path_desc <- "C:/Users/Kossy/OneDrive/Documents/Group4/FinalProject_Group4/DESCRIPTION"
# Read the DESCRIPTION file
desc_content <- read.dcf(path_desc)
# Print the content to verify
print(desc_content)
devtools::document()
?logitreg_group4
devtools::build()
devtools::check()
library(Group4)
devtools::build(vignettes = TRUE)
devtools::install()
library("Group4")
setwd("C:/Users/Kossy/OneDrive/Documents/Group4/Group4")
library(devtools)
library(usethis)
usethis::use_vignette("introduction")
In this vignette, we demonstrated how to use the Group4 package to perform logistic regression analysis, calculate bootstrap confidence intervals, and evaluate model performance using a confusion matrix and associated metrics.
devtools::build_vignettes()
you can find the reference [here]<https://chatgpt.com/share/674f9710-950c-8010-ab01-c910f66608bb>
you can find the reference [here]<https://chatgpt.com/share/674f9710-950c-8010-ab01-c910f66608bb>
devtools::install(build_vignettes = TRUE)
devtools::install(build_vignettes = TRUE)
browseVignettes("Group4")
browseVignettes("Group4")
devtools::build_vignettes()
devtools::install(build_vignettes = TRUE)
browseVignettes("Group4")
devtools::build_vignettes()
devtools::install(build_vignettes = TRUE)
browseVignettes("Group4")
